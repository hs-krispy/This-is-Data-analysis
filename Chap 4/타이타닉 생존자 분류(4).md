## 모델 검증

#### K-fold 교차검증

```python
from sklearn.model_selection import KFold
k = 5
cv = KFold(k, shuffle=True, random_state=0)
auc_history = []
for train_data_row, test_data_row in cv.split(whole_df_encoded):
    df_train = whole_df_encoded.iloc[train_data_row]
    df_test = whole_df_encoded.iloc[test_data_row]
    splited_x_train, splited_y_train = df_train.loc[:, df_train.columns != 'survived'].values, df_train['survived'].values
    splited_x_test, splited_y_test = df_test.loc[:, df_test.columns != 'survived'].values, df_test['survived'].values
    lr = LogisticRegression(random_state=0)
    lr.fit(splited_x_train, splited_y_train)
    y_pred = lr.predict(splited_x_test)
    y_pred_probability = lr.predict_proba(splited_x_test)[:, 1]
    false_positive_rate, true_positive_rate, thresholds = roc_curve(splited_y_test, y_pred_probability)
    roc_auc = roc_auc_score(splited_y_test, y_pred_probability)
    auc_history.append(roc_auc)
    
plt.xlabel("Each K-fold")
plt.ylabel("AUC of splited test data")
plt.plot(range(1, k+1), auc_history)
```

<img src="https://user-images.githubusercontent.com/58063806/99897561-d5207200-2cdd-11eb-9f8e-98a8baa9f4aa.JPG" width=60%/>

교처 검증시에 AUC를 K번째 반복마다 기록한 결과를 보면 AUC가 큰 폭으로 변화하는 것을 볼 수 있음 (다소 불안정한 모델)

- 데이터의 개수가 적기 때문에 발생하는 현상
- 모든 경우에서 test AUC가 0.8 이상의 수치를 기록 (과적합이 발생했지만 대체로 높은 정확도를 가지는 모델)

#### 학습 곡선

- 학습 데이터의 샘플의 개수가 증가함에 따라 학습과 테스트 점수가 어떻게 변화하는지를 관찰

```python
import scikitplot as skplt
skplt.estimators.plot_learning_curve(lr, x_train, y_train)
plt.show()
```

<img src="https://user-images.githubusercontent.com/58063806/99897662-c25a6d00-2cde-11eb-857c-35e17470d158.JPG" width=60%/>

데이터가 300개가 넘어가면 과적합의 위험이 낮아지는 것을 볼 수 있음