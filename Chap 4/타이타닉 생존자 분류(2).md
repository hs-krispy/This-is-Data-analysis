### 전처리

**결측값 처리**

- 결측이 존재하는 데이터들을 삭제
- 평균값 혹은 중앙값이나 최빈값 등의 임의의 수치로 대체

```python
replace_mean = df_train[df_train['age'] > 0]['age'].mean()
df_train['age'] = df_train['age'].fillna(replace_mean)
df_test['age'] = df_test['age'].fillna(replace_mean)

embarked_mode = df_train['embarked'].value_counts().index[0]
df_train['embarked'] = df_train['embarked'].fillna(embarked_mode)
df_test['embarked'] = df_test['embarked'].fillna(embarked_mode)

whole_df = df_train.append(df_test)
train_idx_num = len(df_train)

whole_df_encoded = pd.get_dummies(whole_df)
df_train = whole_df_encoded[:train_idx_num]
df_test = whole_df_encoded[train_idx_num:]

df_train.head()
```

age 피처에 있어서 결측값을 평균값으로 대체

embarked 피처에 있어서 결측값을 최빈값으로 대체하고  원-핫 인코딩 방법으로 범주형 변수를 변환

<img src="https://user-images.githubusercontent.com/58063806/99675009-10425b80-2aba-11eb-94ad-d25e333840de.JPG" width=8%  />

<img src="https://user-images.githubusercontent.com/58063806/99675007-0fa9c500-2aba-11eb-8ea8-43a1285a4174.JPG" width=30%/>

### 로지스틱 회귀 모델

기존 회귀 분석의 예측값 Y를 0 ~ 1사이의 값으로 제한해서 0.5보다 크면 1, 0.5보다 작으면 0으로 분류

- 계수 분석을 통한 피처의 영향력 해석이 용이

```python
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
x_train, y_train = df_train.loc[:, df_train.columns != 'survived'].values, df_train['survived'].values
x_test, y_test = df_test.loc[:, df_test.columns != 'survived'].values, df_test['survived'].values
lr = LogisticRegression(random_state=0)
lr.fit(x_train, y_train)
y_pred = lr.predict(x_test)
y_pred_probability = lr.predict_proba(x_test)[:, 1]
print("Accuracy: %.2f" % accuracy_score(y_test, y_pred))
print("Precision: %.3f" % precision_score(y_test, y_pred))
print("Recall: %.3f" % recall_score(y_test, y_pred))
print("F1: %.3f" % f1_score(y_test, y_pred))
# Accuracy: 0.80
# Precision: 0.756
# Recall: 0.673
# F1: 0.712
```

<img src="https://user-images.githubusercontent.com/58063806/99676757-3e289f80-2abc-11eb-8ead-8ae7384c05e6.JPG" width=30% />

**레이블 0, 1 중 관심 범주를 1이라고 할 때**

- True positives - 1인 값을 1이라 하는 경우 (실제 true인 정답을 true로 예측)
- False Negatives - 1인 값을 0이라 하는 경우 (실제 true인 정답을 false로 예측)
- False Positives - 0인 값을 1이라 하는 경우 (실제 false인 정답을 true로 예측)
- True Negatives - 0인 값을 0이라 하는 경우 (실제 false인 정답을 false로 예측)

<img src="https://user-images.githubusercontent.com/58063806/99678214-ebe87e00-2abd-11eb-95b4-71039a68859a.JPG" width=30% />

[이미지 출처](https://yamalab.tistory.com/50)

정확도 - 전체 중에서 정답을 맞춘 비율 (정확도 역설 - 한쪽에 너무 치우치는 bias에 관해 단점을 가짐)

정밀도 - 모델이 true라고 분류한 것 중 실제 true인 것의 비율

재현율 - 실제 true인 것 중 모델이 true라고 예측한 것의 비율

(정밀도와 재현율은 반비례하는 경향이 있음)

F1 score - 정밀도와 재현도의 조화 평균값 (두 지표를 모두 균형있게 반영)

ROC curve - 재현도와 특이도를 고려한 종합적인 성능을 그래프로 나타내는 것

그래프의 넓이를 계산한 AUC를 성능의 지표로 사용 **(값이 1에 가까울수록 좋은 모델로 평가)**

**confusion_matrix**

```python
from sklearn.metrics import confusion_matrix
confmat = confusion_matrix(y_true=y_test, y_pred=y_pred)
print(confmat)
# [[214  32]
# [ 48  99]]
from sklearn.metrics import roc_curve, roc_auc_score
# 분류 직전의 확률값 y_pred_probability를 사용
false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred_probability)
roc_auc = roc_auc_score(y_test, y_pred_probability)
print("AUC l %.3f" % roc_auc)
# AUC l 0.837

plt.rcParams['figure.figsize'] = [5, 4]
plt.plot(false_positive_rate, true_positive_rate, label="ROC curve (area = %0.3f)" % roc_auc, color="r", linewidth=4.0)
plt.plot([0, 1], [0, 1], 'k--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.0])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC curve of Logistic regression')
plt.legend(loc="lower right")
```

<img src="https://user-images.githubusercontent.com/58063806/99681119-230c5e80-2ac1-11eb-9d96-23f7dee18d44.JPG" width=50% />

### DecisionTree

```python
from sklearn.tree import DecisionTreeClassifier
dtc = DecisionTreeClassifier()
dtc.fit(x_train, y_train)
y_pred = dtc.predict(x_test)
y_pred_probability = dtc.predict_proba(x_test)[:, 1]
print("Accuracy: %.2f" % accuracy_score(y_test, y_pred))
print("Precision: %.3f" % precision_score(y_test, y_pred))
print("Recall: %.3f" % recall_score(y_test, y_pred))
print("F1: %.3f" % f1_score(y_test, y_pred))
# Accuracy: 0.74
# Precision: 0.669
# Recall: 0.619
# F1: 0.643

false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred_probability)
roc_auc = roc_auc_score(y_test, y_pred_probability)
print("AUC l %.3f" % roc_auc)
# AUC l 0.732

plt.rcParams['figure.figsize'] = [5, 4]
plt.plot(false_positive_rate, true_positive_rate, label="ROC curve (area = %0.3f)" % roc_auc, color="r", linewidth=4.0)
plt.plot([0, 1], [0, 1], 'k--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.0])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC curve of Logistic regression')
plt.legend(loc="lower right")
```

<img src="https://user-images.githubusercontent.com/58063806/99684579-f3f7ec00-2ac4-11eb-97b6-a6506a1d07fc.JPG" style="zoom:50%;" />

로지스틱 회귀 모델에 비해 모든 평가지표가 낮은 것을 볼 수 있음
